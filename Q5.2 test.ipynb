{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fc4547",
   "metadata": {},
   "source": [
    "## Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7865771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import imghdr\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad06dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5237f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = ImageDataGenerator(rescale = 1./255, shear_range = 0.1, zoom_range = 0.1)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61dc16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = image_generator.flow_from_directory('chest_xray/train', \n",
    "                                                 class_mode='binary', \n",
    "                                                 batch_size = batch_size, \n",
    "                                                 classes = ['NORMAL', 'PNEUMONIA'], \n",
    "                                                 color_mode = 'grayscale', \n",
    "                                                 shuffle=False, \n",
    "                                                 target_size=(256, 256))\n",
    "\n",
    "val_data = test_generator.flow_from_directory('chest_xray/val', \n",
    "                                              class_mode='binary', \n",
    "                                              batch_size = batch_size, \n",
    "                                              classes = ['NORMAL', 'PNEUMONIA'], \n",
    "                                              color_mode = 'grayscale', \n",
    "                                              shuffle=False, \n",
    "                                              target_size=(256, 256))\n",
    "\n",
    "test_data = test_generator.flow_from_directory('chest_xray/test', \n",
    "                                               class_mode='binary', \n",
    "                                               batch_size = batch_size, \n",
    "                                               classes = ['NORMAL', 'PNEUMONIA'], \n",
    "                                               color_mode = 'grayscale', \n",
    "                                               shuffle=False, \n",
    "                                               target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd53de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5216,), dtype=int32, numpy=array([0, 1, 1, ..., 0, 1, 1])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.shuffle(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f5adf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af5ccd",
   "metadata": {},
   "source": [
    "## Label Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d46dd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b3a651c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091407f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "batch_index = 0\n",
    "\n",
    "while batch_index <= train_data.batch_index:\n",
    "    data = train_data.next()\n",
    "    data_list.append(data[0])\n",
    "    print(batch_index)\n",
    "    batch_index = batch_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ef4218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new = data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d68ca60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.0627451 ]\n",
      "  [0.12787947]\n",
      "  [0.19824085]\n",
      "  ...\n",
      "  [0.37490547]\n",
      "  [0.36672753]\n",
      "  [0.35928303]]\n",
      "\n",
      " [[0.0627451 ]\n",
      "  [0.12789483]\n",
      "  [0.19825402]\n",
      "  ...\n",
      "  [0.374904  ]\n",
      "  [0.36672536]\n",
      "  [0.35928667]]\n",
      "\n",
      " [[0.06317858]\n",
      "  [0.12087499]\n",
      "  [0.19224645]\n",
      "  ...\n",
      "  [0.3764266 ]\n",
      "  [0.369469  ]\n",
      "  [0.36231443]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.16571997]\n",
      "  [0.16729784]\n",
      "  [0.16777998]\n",
      "  ...\n",
      "  [0.40001008]\n",
      "  [0.40782538]\n",
      "  [0.40332448]]\n",
      "\n",
      " [[0.18382895]\n",
      "  [0.18102622]\n",
      "  [0.18353043]\n",
      "  ...\n",
      "  [0.4352464 ]\n",
      "  [0.44460127]\n",
      "  [0.43529415]]\n",
      "\n",
      " [[0.1838297 ]\n",
      "  [0.18102548]\n",
      "  [0.18353117]\n",
      "  ...\n",
      "  [0.43524933]\n",
      "  [0.44459903]\n",
      "  [0.43529415]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_new[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b76e17",
   "metadata": {},
   "source": [
    "## Fir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5d0ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae7cd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63e5fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(8, (3,3), 1, activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "786f712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a0dc632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 8)       80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 8)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 826,401\n",
      "Trainable params: 826,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6dd37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = np.unique(train_data.classes)\n",
    "classes = train_data.classes\n",
    "\n",
    "weights = compute_class_weight(class_weight = 'balanced', classes= unique_classes, y = classes)\n",
    "\n",
    "class_weights = dict(zip( np.unique(train_data.classes), weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7006a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLHC\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\MLHC\\lib\\site-packages\\keras\\engine\\data_adapter.py:1623\u001b[0m, in \u001b[0;36m_make_class_weight_map_fn.<locals>._class_weights_map_fn\u001b[1;34m(*data)\u001b[0m\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mis_nested(y):\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`class_weight` is only supported for Models with a single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1621\u001b[0m     )\n\u001b[1;32m-> 1623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1625\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`class_weight` not supported for 3+ dimensional targets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1626\u001b[0m     )\n\u001b[0;32m   1628\u001b[0m y_classes \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39msmart_cond\u001b[38;5;241m.\u001b[39msmart_cond(\n\u001b[0;32m   1629\u001b[0m     y\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mshape(y)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1630\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: backend\u001b[38;5;241m.\u001b[39margmax(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: tf\u001b[38;5;241m.\u001b[39mcast(backend\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), tf\u001b[38;5;241m.\u001b[39mint64),\n\u001b[0;32m   1632\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_data_new, epochs=20, validation_data = val_data, class_weight = class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLHC]",
   "language": "python",
   "name": "conda-env-MLHC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
